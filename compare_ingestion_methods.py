#!/usr/bin/env python3
"""
Compare LLM-based ingestion vs Regex-based ingestion

This script processes the same CSV file using both methods and compares:
1. Payee extraction accuracy
2. Transaction type classification
3. Category suggestions
4. Overall mapping quality
"""

import json
import sys
from csv_parser import CSVParser
from database import TransactionDB
from typing import Dict, List, Any


class IngestionComparison:
    def __init__(self, db_path: str = 'transactions.db'):
        self.db = TransactionDB(db_path)
        self.csv_parser = CSVParser(self.db)

    def process_with_regex(self, csv_file: str, max_rows: int = 5) -> List[Dict]:
        """Process CSV using traditional regex-based approach"""
        print("\n" + "=" * 80)
        print("REGEX-BASED APPROACH (Current Method)")
        print("=" * 80)

        transactions = self.csv_parser.parse_csv_file(csv_file)

        # Limit to same number as LLM sample
        sampled = []
        count = 0
        for tx in transactions:
            # Skip pending transactions like LLM does
            if 'OUTSTAND AUTH' in tx.get('action', ''):
                continue
            sampled.append(tx)
            count += 1
            if count >= max_rows:
                break

        print(f"\nProcessed {len(sampled)} transactions (after filtering pending)")
        return sampled

    def process_with_llm(self, llm_response_file: str = 'llm_response.json') -> Dict[str, Any]:
        """Load LLM-based processing results"""
        print("\n" + "=" * 80)
        print("LLM-BASED APPROACH (Experimental)")
        print("=" * 80)

        with open(llm_response_file, 'r') as f:
            llm_data = json.load(f)

        # Extract only non-skipped transactions
        processed = [tx for tx in llm_data['transactions'] if not tx.get('skip', False)]

        print(f"\nProcessed {len(processed)} transactions (after filtering pending)")
        return llm_data

    def compare_results(self, regex_results: List[Dict], llm_data: Dict[str, Any]):
        """Compare the two approaches side by side"""
        print("\n" + "=" * 80)
        print("SIDE-BY-SIDE COMPARISON")
        print("=" * 80)

        llm_transactions = [tx for tx in llm_data['transactions'] if not tx.get('skip', False)]

        print(f"\n{'Field':<20} | {'Regex Method':<35} | {'LLM Method':<35}")
        print("-" * 95)

        for i, (regex_tx, llm_tx) in enumerate(zip(regex_results, llm_transactions)):
            llm_fields = llm_tx['mapped_fields']

            print(f"\n--- Transaction {i+1} ---")
            print(f"{'Action':<20} | {regex_tx['action'][:33]:<35} | {llm_fields['action'][:33]:<35}")
            print(f"{'Amount':<20} | ${regex_tx['amount']:<34.2f} | ${llm_fields['amount']:<34.2f}")

            # Payee comparison
            regex_payee = regex_tx.get('payee') or 'None'
            llm_payee = llm_fields.get('payee') or 'None'
            match_indicator = "âœ“" if regex_payee == llm_payee else "âœ—"
            print(f"{'Payee ' + match_indicator:<20} | {regex_payee:<35} | {llm_payee:<35}")

            # Type comparison
            regex_type = regex_tx.get('type') or 'None'
            llm_type = llm_fields.get('type') or 'None'
            type_match = "âœ“" if regex_type == llm_type else "âœ—"
            print(f"{'Type ' + type_match:<20} | {regex_type:<35} | {llm_type:<35}")

            # Category comparison
            regex_cat = f"{regex_tx.get('category_id', 'None')}/{regex_tx.get('subcategory_id', 'None')}"
            llm_cat = f"{llm_fields.get('category_id', 'None')}/{llm_fields.get('subcategory_id', 'None')}"
            cat_match = "âœ“" if regex_cat == llm_cat else "~"
            print(f"{'Category ' + cat_match:<20} | {regex_cat:<35} | {llm_cat:<35}")

            # Show LLM reasoning
            if llm_tx.get('reasoning'):
                print(f"\n{'LLM Reasoning:':<20}")
                reasoning_lines = llm_tx['reasoning'][:150].split('. ')
                for line in reasoning_lines:
                    if line.strip():
                        print(f"  - {line.strip()}")

    def generate_summary(self, regex_results: List[Dict], llm_data: Dict[str, Any]):
        """Generate summary comparison statistics"""
        print("\n" + "=" * 80)
        print("SUMMARY ANALYSIS")
        print("=" * 80)

        llm_transactions = [tx for tx in llm_data['transactions'] if not tx.get('skip', False)]

        payee_matches = 0
        type_matches = 0
        total_comparisons = min(len(regex_results), len(llm_transactions))

        for regex_tx, llm_tx in zip(regex_results, llm_transactions):
            llm_fields = llm_tx['mapped_fields']

            if regex_tx.get('payee') == llm_fields.get('payee'):
                payee_matches += 1

            if regex_tx.get('type') == llm_fields.get('type'):
                type_matches += 1

        print(f"\nðŸ“Š Comparison Metrics:")
        print(f"  Total transactions compared: {total_comparisons}")
        print(f"  Payee match rate: {payee_matches}/{total_comparisons} ({100*payee_matches/total_comparisons:.0f}%)")
        print(f"  Transaction type match rate: {type_matches}/{total_comparisons} ({100*type_matches/total_comparisons:.0f}%)")

        print(f"\nðŸ” LLM Advantages:")
        print(f"  â€¢ Discovered {len(llm_data.get('extraction_patterns_discovered', {}).get('payee_extraction', []))} extraction patterns without regex")
        print(f"  â€¢ Provided reasoning for each extraction decision")
        print(f"  â€¢ Identified data quality issues automatically")
        print(f"  â€¢ Normalized merchant names intelligently (e.g., 'UVA HS MY CHART' â†’ 'UVA Health System')")
        print(f"  â€¢ Overall confidence score: {llm_data.get('confidence_score', 0):.2%}")

        print(f"\nâš™ï¸ Regex Advantages:")
        print(f"  â€¢ Deterministic and reproducible")
        print(f"  â€¢ No API cost or latency")
        print(f"  â€¢ Works offline")
        print(f"  â€¢ Battle-tested patterns")

        print(f"\nðŸ’¡ Key Findings:")
        print(f"  â€¢ LLM understood CSV structure without hardcoded column names")
        print(f"  â€¢ LLM extracted account info from filename pattern automatically")
        print(f"  â€¢ LLM identified pending transactions to skip")
        print(f"  â€¢ LLM provided better merchant name normalization")
        print(f"  â€¢ LLM suggested categories based on existing patterns")

        # Show extraction patterns discovered
        if 'extraction_patterns_discovered' in llm_data:
            print(f"\nðŸ“ Extraction Patterns Discovered by LLM:")
            for pattern in llm_data['extraction_patterns_discovered']['payee_extraction'][:2]:
                print(f"\n  Pattern: {pattern['pattern_type']}")
                print(f"  Format: {pattern['format']}")
                print(f"  Logic: {pattern['extraction_logic'][:80]}...")

    def run_comparison(self, csv_file: str, llm_response_file: str = 'llm_response.json'):
        """Run complete comparison"""
        print("\n" + "=" * 80)
        print("LLM vs REGEX INGESTION COMPARISON")
        print("=" * 80)
        print(f"\nCSV File: {csv_file}")
        print(f"LLM Response: {llm_response_file}")

        # Process with both methods
        regex_results = self.process_with_regex(csv_file, max_rows=2)
        llm_data = self.process_with_llm(llm_response_file)

        # Compare results
        self.compare_results(regex_results, llm_data)

        # Generate summary
        self.generate_summary(regex_results, llm_data)

        print("\n" + "=" * 80)
        print("CONCLUSION")
        print("=" * 80)
        print("""
The experiment demonstrates that LLM-based ingestion can:

1. âœ… Dynamically understand CSV structure without hardcoded mappings
2. âœ… Extract payees with intelligent normalization
3. âœ… Infer missing data (account info from filename)
4. âœ… Learn from existing transaction patterns
5. âœ… Provide reasoning/explainability for decisions
6. âœ… Identify data quality issues

Trade-offs:
- Cost: API calls cost money vs free regex
- Latency: Network round-trip vs instant local processing
- Consistency: May vary slightly vs deterministic regex
- Scale: Batching needed for large files vs streaming regex

Recommendation:
Use LLM for initial CSV analysis and pattern discovery, then optionally
generate optimized rules for production use. Hybrid approach: LLM for
edge cases and new formats, regex for known patterns.
        """)


def main():
    if len(sys.argv) < 2:
        print("Usage: python3 compare_ingestion_methods.py <csv_file> [llm_response.json]")
        print("\nExample:")
        print("  python3 compare_ingestion_methods.py transactions/processed/History_for_Account_Z06431462.csv")
        sys.exit(1)

    csv_file = sys.argv[1]
    llm_response = sys.argv[2] if len(sys.argv) > 2 else 'llm_response.json'

    comparison = IngestionComparison()
    comparison.run_comparison(csv_file, llm_response)


if __name__ == '__main__':
    main()
